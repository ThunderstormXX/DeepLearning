{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFTMJ2v-5YpN"
      },
      "source": [
        "# Homework 2. Training networks in PyTorch\n",
        "\n",
        "Это домашнее задание посвящено отработки навыков по написанию и обучению нейронных сетей. Ваше задание реализовать обучение нейронной сети и выполнить задания по анализу сети в конце ноутбука. Удачи!\n",
        "\n",
        "<font color='red'> **Дедлайн 4 октября 23:59 (жесткий)**  </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3dj1mfT5Yp4"
      },
      "source": [
        "### Data loading in pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UKLLAvNt5Yp5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch.utils.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "h626FYAm5Yp6"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2oqonVb5Yp7"
      },
      "source": [
        "You will works with a MNIST dataset. It contains grayscale images of handwritten digits of size 28 x 28. The number of training objects is 60000.\n",
        "\n",
        "\n",
        "In pytorch, there is a special module to download MNIST. But for us it is more convinient to load the data ourselves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3vZ3StbV5Yp7"
      },
      "outputs": [],
      "source": [
        "from utils import load_mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bOxvlgne5Yp9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading train-images-idx3-ubyte.gz\n",
            "Downloading train-labels-idx1-ubyte.gz\n",
            "Downloading t10k-images-idx3-ubyte.gz\n",
            "Downloading t10k-labels-idx1-ubyte.gz\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train, X_test, y_test = load_mnist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q6eiPbL5Yp-"
      },
      "source": [
        "The code below prepares short data (train and val) for seminar purposes (use this data to quickly learn model on CPU and to tune the hyperparameters). Also, we prepare the full data (train_full and test) to train a final model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0IJS2adK5Yp_",
        "outputId": "be9d80dc-2484-4c7b-ffad-d82b84692f91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 1, 28, 28)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# shuffle data\n",
        "np.random.seed(0)\n",
        "idxs = np.random.permutation(np.arange(X_train.shape[0]))\n",
        "X_train, y_train = X_train[idxs], y_train[idxs]\n",
        "\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYzxQ2Mf5Yp_"
      },
      "source": [
        "Pytorch offers convinient class DataLoader for mini batch generation. You should pass instance of Tensor Dataset to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oOmqt8aE5Yp_"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_129838/2761436466.py:3: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  torch.from_numpy(y).long())\n"
          ]
        }
      ],
      "source": [
        "def get_loader(X, y, batch_size=64):\n",
        "    train = torch.utils.data.TensorDataset(torch.from_numpy(X).float(),\n",
        "                                       torch.from_numpy(y).long())\n",
        "    train_loader = torch.utils.data.DataLoader(train,\n",
        "                                               batch_size=batch_size)\n",
        "    return train_loader\n",
        "\n",
        "# for final model:\n",
        "train_loader_full = get_loader(X_train, y_train)\n",
        "test_loader = get_loader(X_test, y_test)\n",
        "# for validation purposes:\n",
        "train_loader = get_loader(X_train[:15000], y_train[:15000])\n",
        "val_loader = get_loader(X_train[15000:30000], y_train[15000:30000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bOfwqdwJ5YqA",
        "outputId": "f41c6b2c-c1fe-48b6-8382-e5980d16d843"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([15000, 1, 28, 28])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check number of objects\n",
        "val_loader.dataset.tensors[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRoL5vqr5YqB"
      },
      "source": [
        "### Building LeNet-5\n",
        "\n",
        "Convolutional layer (from Anton Osokin's presentation):\n",
        "![slide](https://github.com/nadiinchi/dl_labs/raw/master/convolution.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WokmLD85YqB"
      },
      "source": [
        "You need to implement Lenet-5:\n",
        "\n",
        "![Архитектура LeNet-5](https://www.researchgate.net/profile/Vladimir_Golovko3/publication/313808170/figure/fig3/AS:552880910618630@1508828489678/Architecture-of-LeNet-5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc-cF7o35YqD"
      },
      "source": [
        "Construct a network according to the image and code examples given above. Use ReLU nonlinearity (after all linear and convolutional layers). The network must support multiplying the number of convolutions in each convolutional layer by k.\n",
        "\n",
        "Please note that on the scheme the size of the image is 32 x 32 but in our code the size is 28 x 28.\n",
        "\n",
        "Do not apply softmax at the end of the forward pass!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWfeNQ9gPhXo"
      },
      "source": [
        "### <font color='red'>[TODO] Написание архитектуры Le-Net-5 </font>\n",
        "\n",
        "В этой части вам нужно реализовать архитектуру Le-Net-5, но учтите, что на вход изображения приходит 28x28.\n",
        "\n",
        "Для того, написать архитектуру используйте [nn.Conv2D](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html), [nn.AvgPool2d](https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html), [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html). Ориентируйтесь на картинку сверху в реализации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "collapsed": true,
        "id": "k9AXOaVh5YqE"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, k=1):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pooling1 = nn.AvgPool2d(kernel_size=15, stride=1) # ВТФ, как сделать 14 на 14 со stride =2 ??\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pooling2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.layer1 = nn.Linear(in_features=16*5*5, out_features=120) \n",
        "        self.layer2 = nn.Linear(in_features=120, out_features=84)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.layer3 = nn.Linear(in_features=84, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pooling1(self.relu1(self.conv1(x))) ;print(x.size())\n",
        "        x = self.pooling2(self.relu2(self.conv2(x))) ;print(x.size())\n",
        "        x = x.view(x.size(0), -1)  ; print(x.size())# to 1 dim \n",
        "        x = self.layer1(x); print(x.size())\n",
        "        x = self.layer2(x);print(x.size())\n",
        "        x = self.relu3(x);print(x.size())\n",
        "        x = self.layer3(x);print(x.size())\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4BYDgVO5YqE"
      },
      "source": [
        "Let's count the number of the parameters in the network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "collapsed": true,
        "id": "DMqTaKi_5YqF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 6, 14, 14])\n",
            "torch.Size([1, 16, 5, 5])\n",
            "torch.Size([1, 400])\n",
            "torch.Size([1, 120])\n",
            "torch.Size([1, 84])\n",
            "torch.Size([1, 84])\n",
            "torch.Size([1, 10])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.0382, -0.0247,  0.0658, -0.0872,  0.0890, -0.0825,  0.0209, -0.0027,\n",
              "         -0.1216,  0.0607]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn = CNN( )\n",
        "x = torch.randn(1,1, 28, 28)\n",
        "cnn.forward(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "collapsed": true,
        "id": "JobCjm_Z5YqG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "61562"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(param.data.numpy().size for param \\\n",
        "               in model.parameters() if param.requires_grad)\n",
        "\n",
        "count_parameters(cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p50aWdYI5YqG"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO04799z5YqH"
      },
      "source": [
        "Let's define the loss function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "collapsed": true,
        "id": "xeBFcssY5YqH"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss() # loss includes softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "500YiRwa5YqI"
      },
      "source": [
        "Also, define a device where to store the data and the model (cpu or gpu):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "collapsed": true,
        "id": "3HQo_6Kb5YqJ"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cpu')\n",
        "# device = torch.device('cuda') # Uncomment this to run on GPU\n",
        "cnn = cnn.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK9sl8w_5YqK"
      },
      "source": [
        "During training, we will control the quality on the training and validation set. This produces duplicates of the code. That's why we will define a function evaluate_loss_acc to evaluate our model on different data sets. In the same manner, we define function train_epoch to perform one training epoch on traiing data. Please note that we will compute the training loss _after_ each epoch (not averaging it during epoch).\n",
        "\n",
        "In the propotypes, train and eval modes are noted. In our case, we don't need them (because we don't use neither dropout nor batch normalization). However, we will switch the regime so you can use this code in the future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-9aShtYQWkt"
      },
      "source": [
        "### <font color='red'>[TODO] Реализуйте функции обучение модели </font>\n",
        "\n",
        "В части вам нужно написать циклы обучения моделей, вы можете ориентировать на ноутбук семинара при их выполнении"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5dQn4HuD5YqL"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, optimizer, train_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    for each batch\n",
        "    performs forward and backward pass and parameters update\n",
        "\n",
        "    Input:\n",
        "    model: instance of model (example defined above)\n",
        "    optimizer: instance of optimizer (defined above)\n",
        "    train_loader: instance of DataLoader\n",
        "\n",
        "    Returns:\n",
        "    nothing\n",
        "\n",
        "    Do not forget to set net to train mode!\n",
        "    \"\"\"\n",
        "    ### your code here\n",
        "\n",
        "\n",
        "def evaluate_loss_acc(loader, model, criterion, device):\n",
        "    \"\"\"\n",
        "    Evaluates loss and accuracy on the whole dataset\n",
        "\n",
        "    Input:\n",
        "    loader:  instance of DataLoader\n",
        "    model: instance of model (examle defined above)\n",
        "\n",
        "    Returns:\n",
        "    (loss, accuracy)\n",
        "\n",
        "    Do not forget to set net to eval mode!\n",
        "    \"\"\"\n",
        "    ### your code here\n",
        "    \n",
        "\n",
        "def train(model, opt, train_loader, test_loader, criterion, n_epochs, \\\n",
        "          device, verbose=True):\n",
        "    \"\"\"\n",
        "    Performs training of the model and prints progress\n",
        "\n",
        "    Input:\n",
        "    model: instance of model (example defined above)\n",
        "    opt: instance of optimizer\n",
        "    train_loader: instance of DataLoader\n",
        "    test_loader: instance of DataLoader (for evaluation)\n",
        "    n_epochs: int\n",
        "\n",
        "    Returns:\n",
        "    4 lists: train_log, train_acc_log, val_log, val_acc_log\n",
        "    with corresponding metrics per epoch\n",
        "    \"\"\"\n",
        "    train_log, train_acc_log = [], []\n",
        "    val_log, val_acc_log = [], []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        train_epoch(model, opt, train_loader, criterion, device)\n",
        "        train_loss, train_acc = evaluate_loss_acc(train_loader,\n",
        "                                                  model, criterion,\n",
        "                                                  device)\n",
        "        val_loss, val_acc = evaluate_loss_acc(test_loader, model,\n",
        "                                              criterion, device)\n",
        "\n",
        "        train_log.append(train_loss)\n",
        "        train_acc_log.append(train_acc)\n",
        "\n",
        "        val_log.append(val_loss)\n",
        "        val_acc_log.append(val_acc)\n",
        "\n",
        "        if verbose:\n",
        "             print (('Epoch [%d/%d], Loss (train/test): %.4f/%.4f,'+\\\n",
        "               ' Acc (train/test): %.4f/%.4f' )\n",
        "                   %(epoch+1, n_epochs, \\\n",
        "                     train_loss, val_loss, train_acc, val_acc))\n",
        "\n",
        "    return train_log, train_acc_log, val_log, val_acc_log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIl21h4g5YqM"
      },
      "source": [
        "### <font color='red'>[TODO] Обучение модели </font>\n",
        "\n",
        "Train the neural network, using defined functions. Use Adam as an optimizer, learning_rate=0.001, number of epochs = 20. For hold out, use val_loader, not test_loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "g9Z-1m-45YqN"
      },
      "outputs": [],
      "source": [
        "### your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjpBaZ7fSiP7"
      },
      "source": [
        "### <font color='red'>[TODO] Проведите эксперименты с моделью </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE5cJCEc5Yqq"
      },
      "source": [
        "\n",
        "### Choosing  learning_rate and batch_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_plUpWK5Yqq"
      },
      "source": [
        "Plot accuracy on the training and testing set v. s. training epoch for different learning parameters: learning rate$ \\in \\{0.0001, 0.001, 0.01\\}$, batch size $\\in \\{64, 256\\}$.\n",
        "\n",
        "The best option is to plot training curves on the left graph and validation curves on the right graph with the shared y axis (use plt.ylim).\n",
        "\n",
        "How do learning rate and batch size affect the final quality of the model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lc5mgJmZ5Yqr"
      },
      "outputs": [],
      "source": [
        "### your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEG3Nu9w5Yqs"
      },
      "source": [
        "### Changing the architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqMV5M1j5Yqs"
      },
      "source": [
        "Try to modify our architecture: increase the number of filters and to reduce the number of fully-connected layers.\n",
        "\n",
        "Insert numbers in the brackets:\n",
        "* LeNet-5 classic (6 and 16 convolutions):  training acc: ( )  validation acc: ( )\n",
        "* Number of convolutions x 4 (24 и 64 convolutions):  training acc: ( )  validation acc: ( )\n",
        "* Removing fully connected layer: the previous network with 1 FC layer: training acc: ( )  validation acc: ( )\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eqpd48i25Yqt"
      },
      "outputs": [],
      "source": [
        "### your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoX-g-5n5Yqu"
      },
      "source": [
        "Choose the learning rate, batch size and the architecture based on your experiments. Train a network on the full dataset and print accuracy on the full test set."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
